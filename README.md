# localRAG

Local RAG is a project that leverages Ollama 3.2, LangChain, and ChromaDB to create a robust system for restaurant reviews and questionnaires. This solution integrates advanced AI capabilities to provide insightful and interactive experiences for users.

## Features

- **Ollama 3.2**: Utilized for natural language understanding and generation.
- **LangChain**: Enables seamless chaining of AI models for complex workflows.
- **ChromaDB**: Provides efficient and scalable vector database support.

## Use Case

This project is designed to assist users in reviewing restaurants and answering related questions with precision and ease.

## Getting Started

Follow the instructions below to set up and run the project:

1. Clone the repository.
2. Install the required dependencies.
3. Configure the environment variables.
4. Run the application.

## Contributing

Contributions are welcome! Feel free to submit issues or pull requests to improve the project.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

